{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNW6QoduDonn5HqhoxrINMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emnaa12/Multi-branch-CNN/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Hqq4qV42I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from resnet3d import Resnet3DBuilder\n",
        "import resnet\n",
        "import keras\n",
        "\n",
        "data_path_l ='/content/drive/My Drive/clean_left'\n",
        "data_path_r ='/content/drive/My Drive/clean_right'\n",
        "\n",
        "data_path_dip ='/content/drive/My Drive/disp'\n",
        "\n",
        "num_classes=10\n",
        "batch_size=16\n",
        "epochs=200\n",
        "train_images=340\n",
        "\n",
        "\n",
        "img_channels=3\n",
        "img_rows=224\n",
        "img_cols=224\n",
        "\n",
        "\n",
        "input_imgen = ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "def generate_generator_multiple(generator,dir1, dir2, dir3, batch_size):\n",
        "    genX1 = generator.flow_from_directory(directory=dir1,target_size=(img_rows,img_cols),\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size=batch_size,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          shuffle=True, seed=42,subset='training')\n",
        "                                          \n",
        "      \n",
        "    genX2 = generator.flow_from_directory(directory=dir2,target_size=(img_rows,img_cols),\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size=batch_size,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          shuffle=True, seed=42,subset='training')\n",
        "    \n",
        "    genX3 = generator.flow_from_directory(directory=dir3,target_size=(img_rows,img_cols),\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          batch_size=batch_size,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          shuffle=True, seed=42,subset='training')\n",
        "    \n",
        "    while True:\n",
        "            X1i = genX1.next()\n",
        "            X2i = genX2.next()\n",
        "            X3i = genX3.next()\n",
        "\n",
        "            Xsum = np.concatenate((X1i[0],X2i[0]), axis=3)\n",
        "            Xsum = np.expand_dims(Xsum, axis=1)\n",
        "            Xsum=np.swapaxes(Xsum,4,1)\n",
        "\n",
        "            yield [Xsum,X3i[0]], [X2i[1],X3i[1]]  #Yield both images and their mutual label\n",
        "            \n",
        "             \n",
        " \n",
        "           \n",
        "inputgenerator=generate_generator_multiple(generator=input_imgen,\n",
        "                                           dir1=data_path_l,\n",
        "                                           dir2=data_path_r,\n",
        "                                           dir3=data_path_dip,\n",
        "                                           batch_size=batch_size)\n",
        "\n",
        "\n",
        "def multi_loss_model():\n",
        "    model_rgb  = Resnet3DBuilder.build_resnet_50((6,img_rows,img_cols,1), num_classes)\n",
        "    model_disp = resnet.ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), num_classes)\n",
        "    custom_resnet_model = Model(inputs=[model_rgb.input,model_disp.input], outputs=[model_rgb.output,model_disp.output])\n",
        "\n",
        "    return custom_resnet_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_resnet_multi_class= multi_loss_model()\n",
        "model_resnet_multi_class.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                 loss=[keras.losses.CategoricalCrossentropy(), keras.losses.CategoricalCrossentropy()],\n",
        "                                  loss_weights=[1., 0.2],\n",
        "                                 metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "\n",
        "history=model_resnet_multi_class.fit_generator(inputgenerator,\n",
        "                       steps_per_epoch= train_images // batch_size,\n",
        "                        epochs = epochs)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}